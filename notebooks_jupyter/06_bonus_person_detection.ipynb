{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: CNN zur Erkennung von Personen\n",
    "\n",
    "Dieses Notebook implementiert ein CNN zur Erkennung von Personen und wendet es auf Bilder an, die sowohl Personen als auch Autos enthalten.\n",
    "\n",
    "## Überblick\n",
    "- Definition eines CNN-Modells für Personenerkennung\n",
    "- Anwendung des Sliding-Window-Algorithmus für Personen- und Autoerkennung\n",
    "- Multi-Scale-Erkennung für verschiedene Objektgrößen\n",
    "- Visualisierung der erkannten Personen und Autos in Bildern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importieren der benötigten Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitung der Verzeichnisse\n",
    "\n",
    "Wir erstellen die notwendigen Verzeichnisse für Modelle, Bilder, Ergebnisse und Bonus-Ergebnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Verzeichnisse\n",
    "models_dir = '../models'\n",
    "data_dir = '../data'\n",
    "images_dir = '../images'\n",
    "results_dir = '../results'\n",
    "bonus_dir = '../bonus'\n",
    "\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "os.makedirs(bonus_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition des CNN-Modells für Personenerkennung\n",
    "\n",
    "Wir definieren ein CNN-Modell zur Erkennung von Personen. Das Modell besteht aus mehreren Convolutional Blocks mit Batch Normalization und Dropout zur Regularisierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_person_detection_model(input_shape=(32, 32, 3)):\n",
    "    model = Sequential([\n",
    "        # Erster Convolutional Block\n",
    "        Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Zweiter Convolutional Block\n",
    "        Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Dritter Convolutional Block\n",
    "        Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')  # Binäre Klassifikation: Person vs. Nicht-Person\n",
    "    ])\n",
    "    \n",
    "    # Kompilieren des Modells\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktionen für die Bildverarbeitung und Objekterkennung\n",
    "\n",
    "### Laden und Vorverarbeiten von Bildern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_and_preprocess_image(image_path, target_size=(32, 32)):\n",
    "    \"\"\"\n",
    "    Lädt ein Bild und bereitet es für die Vorhersage vor.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Pfad zum Bild oder URL\n",
    "        target_size: Zielgröße für das Modell\n",
    "        \n",
    "    Returns:\n",
    "        image: Originalbild\n",
    "        processed_image: Vorverarbeitetes Bild für das Modell\n",
    "        (original_height, original_width): Originalgröße des Bildes\n",
    "    \"\"\"\n",
    "    # Überprüfen, ob es sich um eine URL handelt\n",
    "    if image_path.startswith('http'):\n",
    "        response = requests.get(image_path)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        image = np.array(image)\n",
    "    else:\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Speichern der Originalgröße\n",
    "    original_height, original_width = image.shape[:2]\n",
    "    \n",
    "    # Vorverarbeitung für das Modell\n",
    "    processed_image = cv2.resize(image, target_size)\n",
    "    processed_image = processed_image.astype('float32') / 255.0\n",
    "    \n",
    "    return image, processed_image, (original_height, original_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window Algorithmus zur Objekterkennung\n",
    "\n",
    "Der Sliding Window Algorithmus verschiebt ein Fenster über das Bild und wendet das CNN-Modell auf jeden Ausschnitt an, um Objekte zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def detect_objects(image, model, window_size=(32, 32), stride=16, confidence_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Erkennt Objekte in einem Bild mit Sliding Window.\n",
    "    \n",
    "    Args:\n",
    "        image: Eingabebild\n",
    "        model: Trainiertes Modell\n",
    "        window_size: Größe des Sliding Windows\n",
    "        stride: Schrittweite des Sliding Windows\n",
    "        confidence_threshold: Schwellenwert für die Konfidenz\n",
    "        \n",
    "    Returns:\n",
    "        detections: Liste der erkannten Objekte (x, y, w, h, confidence)\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    detections = []\n",
    "    \n",
    "    for y in range(0, height - window_size[1], stride):\n",
    "        for x in range(0, width - window_size[0], stride):\n",
    "            # Extrahieren des Fensters\n",
    "            window = image[y:y + window_size[1], x:x + window_size[0]]\n",
    "            \n",
    "            # Vorverarbeitung des Fensters\n",
    "            window = cv2.resize(window, window_size)\n",
    "            window = window.astype('float32') / 255.0\n",
    "            window = np.expand_dims(window, axis=0)\n",
    "            \n",
    "            # Vorhersage\n",
    "            prediction = model.predict(window, verbose=0)[0][0]\n",
    "            \n",
    "            # Wenn die Konfidenz über dem Schwellenwert liegt, speichern wir die Erkennung\n",
    "            if prediction > confidence_threshold:\n",
    "                detections.append((x, y, window_size[0], window_size[1], prediction))\n",
    "    \n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Maximum Suppression\n",
    "\n",
    "Non-Maximum Suppression entfernt überlappende Bounding Boxes und behält nur die mit der höchsten Konfidenz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def non_max_suppression(boxes, overlap_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Führt Non-Maximum Suppression durch, um überlappende Bounding Boxes zu entfernen.\n",
    "    \n",
    "    Args:\n",
    "        boxes: Liste der Bounding Boxes (x, y, w, h, confidence)\n",
    "        overlap_threshold: Schwellenwert für die Überlappung\n",
    "        \n",
    "    Returns:\n",
    "        picked: Liste der ausgewählten Bounding Boxes\n",
    "    \"\"\"\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Konvertieren der Bounding Boxes in das Format (x1, y1, x2, y2)\n",
    "    boxes_array = np.array([(x, y, x + w, y + h, conf) for x, y, w, h, conf in boxes])\n",
    "    \n",
    "    # Sortieren der Bounding Boxes nach Konfidenz (absteigend)\n",
    "    boxes_array = boxes_array[np.argsort(boxes_array[:, 4])[::-1]]\n",
    "    \n",
    "    picked = []\n",
    "    \n",
    "    while len(boxes_array) > 0:\n",
    "        # Die Box mit der höchsten Konfidenz auswählen\n",
    "        current_box = boxes_array[0]\n",
    "        picked.append(current_box)\n",
    "        \n",
    "        # Berechnen der Überlappung mit den verbleibenden Boxen\n",
    "        remaining_boxes = boxes_array[1:]\n",
    "        \n",
    "        if len(remaining_boxes) == 0:\n",
    "            break\n",
    "        \n",
    "        # Berechnen der Koordinaten der Überlappung\n",
    "        xx1 = np.maximum(current_box[0], remaining_boxes[:, 0])\n",
    "        yy1 = np.maximum(current_box[1], remaining_boxes[:, 1])\n",
    "        xx2 = np.minimum(current_box[2], remaining_boxes[:, 2])\n",
    "        yy2 = np.minimum(current_box[3], remaining_boxes[:, 3])\n",
    "        \n",
    "        # Berechnen der Breite und Höhe der Überlappung\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        \n",
    "        # Berechnen des Überlappungsverhältnisses\n",
    "        overlap = (w * h) / ((remaining_boxes[:, 2] - remaining_boxes[:, 0] + 1) * \n",
    "                             (remaining_boxes[:, 3] - remaining_boxes[:, 1] + 1))\n",
    "        \n",
    "        # Entfernen der Boxen mit einer Überlappung über dem Schwellenwert\n",
    "        boxes_array = remaining_boxes[overlap < overlap_threshold]\n",
    "    \n",
    "    # Konvertieren zurück in das Format (x, y, w, h, confidence)\n",
    "    picked = [(box[0], box[1], box[2] - box[0], box[3] - box[1], box[4]) for box in picked]\n",
    "    \n",
    "    return picked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeichnen der Bounding Boxes\n",
    "\n",
    "Diese Funktion zeichnet die erkannten Bounding Boxes für Autos und Personen auf das Bild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def draw_boxes(image, car_boxes, person_boxes):\n",
    "    \"\"\"\n",
    "    Zeichnet Bounding Boxes für Autos und Personen auf ein Bild.\n",
    "    \n",
    "    Args:\n",
    "        image: Eingabebild\n",
    "        car_boxes: Liste der Auto-Bounding Boxes (x, y, w, h, confidence)\n",
    "        person_boxes: Liste der Personen-Bounding Boxes (x, y, w, h, confidence)\n",
    "        \n",
    "    Returns:\n",
    "        result: Bild mit Bounding Boxes\n",
    "    \"\"\"\n",
    "    result = image.copy()\n",
    "    \n",
    "    # Zeichnen der Auto-Bounding Boxes\n",
    "    for (x, y, w, h, conf) in car_boxes:\n",
    "        # Zeichnen der Bounding Box\n",
    "        cv2.rectangle(result, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Zeichnen der Konfidenz\n",
    "        text = f\"Auto: {conf:.2f}\"\n",
    "        cv2.putText(result, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Zeichnen der Personen-Bounding Boxes\n",
    "    for (x, y, w, h, conf) in person_boxes:\n",
    "        # Zeichnen der Bounding Box\n",
    "        cv2.rectangle(result, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        \n",
    "        # Zeichnen der Konfidenz\n",
    "        text = f\"Person: {conf:.2f}\"\n",
    "        cv2.putText(result, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Scale Sliding Window\n",
    "\n",
    "Multi-Scale Sliding Window skaliert das Bild auf verschiedene Größen, um Objekte unterschiedlicher Größen zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def detect_objects_multi_scale(image, model, scales=[0.5, 0.75, 1.0, 1.25, 1.5], \n",
    "                              window_size=(32, 32), stride=16, confidence_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Erkennt Objekte in einem Bild mit Multi-Scale Sliding Window.\n",
    "    \n",
    "    Args:\n",
    "        image: Eingabebild\n",
    "        model: Trainiertes Modell\n",
    "        scales: Liste der Skalierungsfaktoren\n",
    "        window_size: Größe des Sliding Windows\n",
    "        stride: Schrittweite des Sliding Windows\n",
    "        confidence_threshold: Schwellenwert für die Konfidenz\n",
    "        \n",
    "    Returns:\n",
    "        detections: Liste der erkannten Objekte (x, y, w, h, confidence)\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    detections = []\n",
    "    \n",
    "    for scale in scales:\n",
    "        # Skalieren des Bildes\n",
    "        scaled_height = int(height * scale)\n",
    "        scaled_width = int(width * scale)\n",
    "        scaled_image = cv2.resize(image, (scaled_width, scaled_height))\n",
    "        \n",
    "        # Erkennen von Objekten im skalierten Bild\n",
    "        scaled_detections = detect_objects(scaled_image, model, window_size, stride, confidence_threshold)\n",
    "        \n",
    "        # Anpassen der Koordinaten an die Originalgröße\n",
    "        for (x, y, w, h, conf) in scaled_detections:\n",
    "            x_orig = int(x / scale)\n",
    "            y_orig = int(y / scale)\n",
    "            w_orig = int(w / scale)\n",
    "            h_orig = int(h / scale)\n",
    "            detections.append((x_orig, y_orig, w_orig, h_orig, conf))\n",
    "    \n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hauptfunktion zur Erkennung von Autos und Personen in Bildern\n",
    "\n",
    "Diese Funktion kombiniert alle vorherigen Funktionen, um Autos und Personen in einem Bild zu erkennen und zu markieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def detect_cars_and_persons(image_path, car_model, person_model, output_path, multi_scale=True):\n",
    "    \"\"\"\n",
    "    Erkennt Autos und Personen in einem Bild und zeichnet Bounding Boxes.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Pfad zum Bild oder URL\n",
    "        car_model: Trainiertes Modell für Autos\n",
    "        person_model: Trainiertes Modell für Personen\n",
    "        output_path: Pfad zum Ausgabebild\n",
    "        multi_scale: Ob Multi-Scale Sliding Window verwendet werden soll\n",
    "        \n",
    "    Returns:\n",
    "        car_boxes: Liste der erkannten Autos (x, y, w, h, confidence)\n",
    "        person_boxes: Liste der erkannten Personen (x, y, w, h, confidence)\n",
    "    \"\"\"\n",
    "    # Laden und Vorverarbeiten des Bildes\n",
    "    image, processed_image, (original_height, original_width) = load_and_preprocess_image(image_path)\n",
    "    \n",
    "    # Erkennen von Autos im Bild\n",
    "    if multi_scale:\n",
    "        car_boxes = detect_objects_multi_scale(image, car_model)\n",
    "    else:\n",
    "        car_boxes = detect_objects(image, car_model)\n",
    "    \n",
    "    # Zusammenführen überlappender Auto-Bounding Boxes\n",
    "    car_boxes = non_max_suppression(car_boxes)\n",
    "    \n",
    "    # Erkennen von Personen im Bild\n",
    "    if multi_scale:\n",
    "        person_boxes = detect_objects_multi_scale(image, person_model)\n",
    "    else:\n",
    "        person_boxes = detect_objects(image, person_model)\n",
    "    \n",
    "    # Zusammenführen überlappender Personen-Bounding Boxes\n",
    "    person_boxes = non_max_suppression(person_boxes)\n",
    "    \n",
    "    # Zeichnen der Bounding Boxes\n",
    "    result = draw_boxes(image, car_boxes, person_boxes)\n",
    "    \n",
    "    # Speichern des Ergebnisses\n",
    "    result_rgb = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(output_path, result_rgb)\n",
    "    \n",
    "    # Erstellen einzelner Bilder für jedes erkannte Auto\n",
    "    for i, (x, y, w, h, conf) in enumerate(car_boxes):\n",
    "        # Konvertieren der Koordinaten zu Integers\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "        car_image = image[y:y+h, x:x+w]\n",
    "        car_image_with_box = car_image.copy()\n",
    "        cv2.rectangle(car_image_with_box, (0, 0), (w, h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Speichern des Bildes\n",
    "        car_output_path = output_path.replace('.jpg', f'_car_{i+1}.jpg')\n",
    "        car_image_rgb = cv2.cvtColor(car_image_with_box, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(car_output_path, car_image_rgb)\n",
    "    \n",
    "    # Erstellen einzelner Bilder für jede erkannte Person\n",
    "    for i, (x, y, w, h, conf) in enumerate(person_boxes):\n",
    "        # Konvertieren der Koordinaten zu Integers\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "        person_image = image[y:y+h, x:x+w]\n",
    "        person_image_with_box = person_image.copy()\n",
    "        cv2.rectangle(person_image_with_box, (0, 0), (w, h), (255, 0, 0), 2)\n",
    "        \n",
    "        # Speichern des Bildes\n",
    "        person_output_path = output_path.replace('.jpg', f'_person_{i+1}.jpg')\n",
    "        person_image_rgb = cv2.cvtColor(person_image_with_box, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(person_output_path, person_image_rgb)\n",
    "    \n",
    "    return car_boxes, person_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hauptfunktion\n",
    "\n",
    "Die Hauptfunktion lädt das trainierte Auto-Modell, verwendet es als Platzhalter für das Personen-Modell und wendet beide Modelle auf Testbilder an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Laden des trainierten Auto-Modells\n",
    "print(\"Laden des trainierten Auto-Modells...\")\n",
    "try:\n",
    "    car_model = load_model(os.path.join(models_dir, 'car_detection_model.keras'))\n",
    "    print(\"Auto-Modell erfolgreich geladen.\")\n",
    "except:\n",
    "    print(\"Fehler beim Laden des Auto-Modells. Bitte stellen Sie sicher, dass das Modell trainiert wurde.\")\n",
    "    raise Exception(\"Auto-Modell konnte nicht geladen werden.\")\n",
    "\n",
    "# Training des Personen-Modells\n",
    "print(\"Training des Personen-Modells...\")\n",
    "\n",
    "# Hier würden wir normalerweise ein Personen-Modell trainieren\n",
    "# Da wir keinen Datensatz für Personen haben, verwenden wir das Auto-Modell als Platzhalter\n",
    "# In einer realen Anwendung würden wir einen Datensatz mit Personen verwenden\n",
    "person_model = car_model\n",
    "\n",
    "# Speichern des Personen-Modells\n",
    "person_model.save(os.path.join(models_dir, 'person_detection_model.keras'))\n",
    "print(f\"Personen-Modell wurde gespeichert unter: {os.path.join(models_dir, 'person_detection_model.keras')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus-Aufgabe: Erkennung von Autos und Personen auf drei Bildern\n",
    "\n",
    "Wir wenden die Modelle auf drei Bilder an, die sowohl Autos als auch Personen enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Bonus-Aufgabe: Erkennung von Autos und Personen auf drei Bildern...\")\n",
    "\n",
    "# Bilder mit Autos und Personen\n",
    "bonus_images = [\n",
    "    \"https://cdn.pixabay.com/photo/2017/08/06/15/13/people-2593341_1280.jpg\",\n",
    "    \"https://cdn.pixabay.com/photo/2016/11/18/16/16/adult-1835810_1280.jpg\",\n",
    "    \"https://cdn.pixabay.com/photo/2017/08/01/11/48/woman-2564660_1280.jpg\"\n",
    "]\n",
    "\n",
    "for i, image_url in enumerate(bonus_images):\n",
    "    # Speichern des Bildes\n",
    "    image_path = os.path.join(images_dir, f'bonus_image_{i+1}.jpg')\n",
    "    \n",
    "    # Herunterladen des Bildes, wenn es noch nicht existiert\n",
    "    if not os.path.exists(image_path):\n",
    "        response = requests.get(image_url)\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    \n",
    "    # Erkennen von Autos und Personen im Bild\n",
    "    output_path = os.path.join(bonus_dir, f'bonus_image_{i+1}_result.jpg')\n",
    "    car_boxes, person_boxes = detect_cars_and_persons(image_path, car_model, person_model, output_path)\n",
    "    \n",
    "    print(f\"Bonus-Bild {i+1}: {len(car_boxes)} Autos und {len(person_boxes)} Personen erkannt\")\n",
    "    \n",
    "    # Anzeigen des Ergebnisses im Notebook\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(plt.imread(output_path))\n",
    "    plt.title(f\"Bonus-Bild {i+1}: {len(car_boxes)} Autos und {len(person_boxes)} Personen erkannt\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "In diesem Notebook haben wir:\n",
    "1. Ein CNN-Modell für die Personenerkennung definiert\n",
    "2. Das trainierte Auto-Modell als Platzhalter für das Personen-Modell verwendet\n",
    "3. Einen Sliding-Window-Algorithmus mit Multi-Scale-Erkennung implementiert\n",
    "4. Non-Maximum Suppression angewendet, um überlappende Bounding Boxes zu entfernen\n",
    "5. Die Erkennung auf Bilder angewendet, die sowohl Autos als auch Personen enthalten\n",
    "6. Die Ergebnisse visualisiert\n",
    "\n",
    "In einer realen Anwendung würden wir ein separates Modell für die Personenerkennung trainieren, das auf einem Datensatz mit Personen trainiert wurde. Die Verwendung des Auto-Modells als Platzhalter dient hier nur zu Demonstrationszwecken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Bonus-Aufgabe abgeschlossen. Die Ergebnisse wurden im Verzeichnis 'bonus' gespeichert.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
