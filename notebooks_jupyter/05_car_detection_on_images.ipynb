{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automerkennung auf Bildern\n",
    "\n",
    "Dieses Notebook implementiert die Automerkennung auf Bildern mit dem trainierten CNN-Modell. Es verwendet einen Sliding-Window-Ansatz mit Multi-Scale-Erkennung, um Autos in Bildern zu lokalisieren und zu markieren.\n",
    "\n",
    "## Überblick\n",
    "- Laden des trainierten CNN-Modells\n",
    "- Implementierung eines Sliding-Window-Algorithmus zur Objekterkennung\n",
    "- Multi-Scale-Erkennung für verschiedene Objektgrößen\n",
    "- Non-Maximum Suppression zur Entfernung überlappender Bounding Boxes\n",
    "- Anwendung auf Testbilder und Visualisierung der Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importieren der benötigten Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitung der Verzeichnisse\n",
    "\n",
    "Wir erstellen die notwendigen Verzeichnisse für Bilder und Ergebnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Verzeichnisse\n",
    "models_dir = '../models'\n",
    "data_dir = '../data'\n",
    "images_dir = '../images'\n",
    "results_dir = '../results'\n",
    "\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden des trainierten Modells\n",
    "\n",
    "Wir laden das in den vorherigen Notebooks trainierte CNN-Modell zur Autoerkennung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Laden des trainierten Modells\n",
    "print(\"Laden des trainierten Modells...\")\n",
    "try:\n",
    "    model = load_model(os.path.join(models_dir, 'car_detection_model.keras'))\n",
    "    print(\"Modell erfolgreich geladen.\")\n",
    "except:\n",
    "    print(\"Fehler beim Laden des Modells. Bitte stellen Sie sicher, dass das Modell trainiert wurde.\")\n",
    "    # In einem Notebook verwenden wir keinen exit(1), sondern werfen eine Exception\n",
    "    raise Exception(\"Modell konnte nicht geladen werden.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktionen für die Bildverarbeitung und Objekterkennung\n",
    "\n",
    "### Laden und Vorverarbeiten von Bildern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_and_preprocess_image(image_path, target_size=(32, 32)):\n",
    "    \"\"\"\n",
    "    Lädt ein Bild und bereitet es für die Vorhersage vor.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Pfad zum Bild oder URL\n",
    "        target_size: Zielgröße für das Modell\n",
    "        \n",
    "    Returns:\n",
    "        image: Originalbild\n",
    "        processed_image: Vorverarbeitetes Bild für das Modell\n",
    "        (original_height, original_width): Originalgröße des Bildes\n",
    "    \"\"\"\n",
    "    # Überprüfen, ob es sich um eine URL handelt\n",
    "    if image_path.startswith('http'):\n",
    "        response = requests.get(image_path)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        image = np.array(image)\n",
    "    else:\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Speichern der Originalgröße\n",
    "    original_height, original_width = image.shape[:2]\n",
    "    \n",
    "    # Vorverarbeitung für das Modell\n",
    "    processed_image = cv2.resize(image, target_size)\n",
    "    processed_image = processed_image.astype('float32') / 255.0\n",
    "    \n",
    "    return image, processed_image, (original_height, original_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window Algorithmus zur Objekterkennung\n",
    "\n",
    "Der Sliding Window Algorithmus verschiebt ein Fenster über das Bild und wendet das CNN-Modell auf jeden Ausschnitt an, um Autos zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def detect_cars(image, model, window_size=(64, 64), stride=32, confidence_threshold=0.6):\n",
    "    \"\"\"\n",
    "    Erkennt Autos in einem Bild mit Sliding Window.\n",
    "    \n",
    "    Args:\n",
    "        image: Eingabebild\n",
    "        model: Trainiertes Modell\n",
    "        window_size: Größe des Sliding Windows\n",
    "        stride: Schrittweite des Sliding Windows\n",
    "        confidence_threshold: Schwellenwert für die Konfidenz\n",
    "        \n",
    "    Returns:\n",
    "        detections: Liste der erkannten Autos (x, y, w, h, confidence)\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    detections = []\n",
    "    \n",
    "    for y in range(0, height - window_size[1], stride):\n",
    "        for x in range(0, width - window_size[0], stride):\n",
    "            # Extrahieren des Fensters\n",
    "            window = image[y:y + window_size[1], x:x + window_size[0]]\n",
    "            \n",
    "            # Vorverarbeitung des Fensters\n",
    "            window = cv2.resize(window, window_size)\n",
    "            window = window.astype('float32') / 255.0\n",
    "            window = np.expand_dims(window, axis=0)\n",
    "            \n",
    "            # Vorhersage\n",
    "            prediction = model.predict(window, verbose=0)[0][0]\n",
    "            \n",
    "            # Wenn die Konfidenz über dem Schwellenwert liegt, speichern wir die Erkennung\n",
    "            if prediction > confidence_threshold:\n",
    "                detections.append((x, y, window_size[0], window_size[1], prediction))\n",
    "    \n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Maximum Suppression\n",
    "\n",
    "Non-Maximum Suppression entfernt überlappende Bounding Boxes und behält nur die mit der höchsten Konfidenz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def non_max_suppression(boxes, overlap_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Führt Non-Maximum Suppression durch, um überlappende Bounding Boxes zu entfernen.\n",
    "    \n",
    "    Args:\n",
    "        boxes: Liste der Bounding Boxes (x, y, w, h, confidence)\n",
    "        overlap_threshold: Schwellenwert für die Überlappung\n",
    "        \n",
    "    Returns:\n",
    "        picked: Liste der ausgewählten Bounding Boxes\n",
    "    \"\"\"\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Konvertieren der Bounding Boxes in das Format (x1, y1, x2, y2)\n",
    "    boxes_array = np.array([(x, y, x + w, y + h, conf) for x, y, w, h, conf in boxes])\n",
    "    \n",
    "    # Sortieren der Bounding Boxes nach Konfidenz (absteigend)\n",
    "    boxes_array = boxes_array[np.argsort(boxes_array[:, 4])[::-1]]\n",
    "    \n",
    "    picked = []\n",
    "    \n",
    "    while len(boxes_array) > 0:\n",
    "        # Die Box mit der höchsten Konfidenz auswählen\n",
    "        current_box = boxes_array[0]\n",
    "        picked.append(current_box)\n",
    "        \n",
    "        # Berechnen der Überlappung mit den verbleibenden Boxen\n",
    "        remaining_boxes = boxes_array[1:]\n",
    "        \n",
    "        if len(remaining_boxes) == 0:\n",
    "            break\n",
    "        \n",
    "        # Berechnen der Koordinaten der Überlappung\n",
    "        xx1 = np.maximum(current_box[0], remaining_boxes[:, 0])\n",
    "        yy1 = np.maximum(current_box[1], remaining_boxes[:, 1])\n",
    "        xx2 = np.minimum(current_box[2], remaining_boxes[:, 2])\n",
    "        yy2 = np.minimum(current_box[3], remaining_boxes[:, 3])\n",
    "        \n",
    "        # Berechnen der Breite und Höhe der Überlappung\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        \n",
    "        # Berechnen des Überlappungsverhältnisses\n",
    "        overlap = (w * h) / ((remaining_boxes[:, 2] - remaining_boxes[:, 0] + 1) * \n",
    "                             (remaining_boxes[:, 3] - remaining_boxes[:, 1] + 1))\n",
    "        \n",
    "        # Entfernen der Boxen mit einer Überlappung über dem Schwellenwert\n",
    "        boxes_array = remaining_boxes[overlap < overlap_threshold]\n",
    "    \n",
    "    # Konvertieren zurück in das Format (x, y, w, h, confidence)\n",
    "    picked = [(box[0], box[1], box[2] - box[0], box[3] - box[1], box[4]) for box in picked]\n",
    "    \n",
    "    return picked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeichnen der Bounding Boxes\n",
    "\n",
    "Diese Funktion zeichnet die erkannten Bounding Boxes auf das Bild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def draw_boxes(image, boxes):\n",
    "    \"\"\"\n",
    "    Zeichnet Bounding Boxes auf ein Bild.\n",
    "    \n",
    "    Args:\n",
    "        image: Eingabebild\n",
    "        boxes: Liste der Bounding Boxes (x, y, w, h, confidence)\n",
    "        \n",
    "    Returns:\n",
    "        result: Bild mit Bounding Boxes\n",
    "    \"\"\"\n",
    "    result = image.copy()\n",
    "    \n",
    "    for (x, y, w, h, conf) in boxes:\n",
    "        # Zeichnen der Bounding Box\n",
    "        cv2.rectangle(result, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Zeichnen der Konfidenz\n",
    "        text = f\"Auto: {conf:.2f}\"\n",
    "        cv2.putText(result, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Scale Sliding Window\n",
    "\n",
    "Multi-Scale Sliding Window skaliert das Bild auf verschiedene Größen, um Objekte unterschiedlicher Größen zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def detect_cars_multi_scale(image, model, scales=[0.5, 0.75, 1.0, 1.25, 1.5, 2.0, 2.5], \n",
    "                           window_size=(64, 64), stride=32, confidence_threshold=0.6):\n",
    "    \"\"\"\n",
    "    Erkennt Autos in einem Bild mit Multi-Scale Sliding Window.\n",
    "    \n",
    "    Args:\n",
    "        image: Eingabebild\n",
    "        model: Trainiertes Modell\n",
    "        scales: Liste der Skalierungsfaktoren\n",
    "        window_size: Größe des Sliding Windows\n",
    "        stride: Schrittweite des Sliding Windows\n",
    "        confidence_threshold: Schwellenwert für die Konfidenz\n",
    "        \n",
    "    Returns:\n",
    "        detections: Liste der erkannten Autos (x, y, w, h, confidence)\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    detections = []\n",
    "    \n",
    "    for scale in scales:\n",
    "        # Skalieren des Bildes\n",
    "        scaled_height = int(height * scale)\n",
    "        scaled_width = int(width * scale)\n",
    "        scaled_image = cv2.resize(image, (scaled_width, scaled_height))\n",
    "        \n",
    "        # Erkennen von Autos im skalierten Bild\n",
    "        scaled_detections = detect_cars(scaled_image, model, window_size, stride, confidence_threshold)\n",
    "        \n",
    "        # Anpassen der Koordinaten an die Originalgröße\n",
    "        for (x, y, w, h, conf) in scaled_detections:\n",
    "            x_orig = int(x / scale)\n",
    "            y_orig = int(y / scale)\n",
    "            w_orig = int(w / scale)\n",
    "            h_orig = int(h / scale)\n",
    "            detections.append((x_orig, y_orig, w_orig, h_orig, conf))\n",
    "    \n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hauptfunktion zur Erkennung von Autos in Bildern\n",
    "\n",
    "Diese Funktion kombiniert alle vorherigen Funktionen, um Autos in einem Bild zu erkennen und zu markieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def detect_and_draw_cars(image_path, model, output_path, multi_scale=True):\n",
    "    \"\"\"\n",
    "    Erkennt Autos in einem Bild und zeichnet Bounding Boxes.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Pfad zum Bild oder URL\n",
    "        model: Trainiertes Modell\n",
    "        output_path: Pfad zum Ausgabebild\n",
    "        multi_scale: Ob Multi-Scale Sliding Window verwendet werden soll\n",
    "        \n",
    "    Returns:\n",
    "        boxes: Liste der erkannten Autos (x, y, w, h, confidence)\n",
    "    \"\"\"\n",
    "    # Laden und Vorverarbeiten des Bildes\n",
    "    image, processed_image, (original_height, original_width) = load_and_preprocess_image(image_path)\n",
    "    \n",
    "    # Erkennen von Autos im Bild\n",
    "    if multi_scale:\n",
    "        boxes = detect_cars_multi_scale(image, model)\n",
    "    else:\n",
    "        boxes = detect_cars(image, model)\n",
    "    \n",
    "    # Zusammenführen überlappender Bounding Boxes\n",
    "    boxes = non_max_suppression(boxes)\n",
    "    \n",
    "    # Zeichnen der Bounding Boxes\n",
    "    result = draw_boxes(image, boxes)\n",
    "    \n",
    "    # Speichern des Ergebnisses\n",
    "    result_rgb = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(output_path, result_rgb)\n",
    "    \n",
    "    # Erstellen einzelner Bilder für jedes erkannte Auto\n",
    "    for i, (x, y, w, h, conf) in enumerate(boxes):\n",
    "        # Convert coordinates to integers to avoid TypeError\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "        car_image = image[y:y+h, x:x+w]\n",
    "        car_image_with_box = car_image.copy()\n",
    "        cv2.rectangle(car_image_with_box, (0, 0), (w, h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Speichern des Bildes\n",
    "        car_output_path = output_path.replace('.jpg', f'_car_{i+1}.jpg')\n",
    "        car_image_rgb = cv2.cvtColor(car_image_with_box, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(car_output_path, car_image_rgb)\n",
    "    \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anwendung auf Testbilder\n",
    "\n",
    "### Aufgabe 2a: Erkennung von Autos auf drei gegebenen Bildern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Aufgabe 2a: Erkennung von Autos auf drei gegebenen Bildern...\")\n",
    "\n",
    "# Erstellen von drei Testbildern mit Autos\n",
    "test_images = [\n",
    "    \"https://cdn.pixabay.com/photo/2016/11/18/12/51/automobile-1834274_1280.jpg\",\n",
    "    \"https://cdn.pixabay.com/photo/2017/03/27/14/56/auto-2179220_1280.jpg\",\n",
    "    \"https://cdn.pixabay.com/photo/2016/04/01/12/16/car-1300629_1280.png\"\n",
    "]\n",
    "\n",
    "for i, image_url in enumerate(test_images):\n",
    "    # Speichern des Bildes\n",
    "    image_path = os.path.join(images_dir, f'test_image_{i+1}.jpg')\n",
    "    \n",
    "    # Herunterladen des Bildes, wenn es noch nicht existiert\n",
    "    if not os.path.exists(image_path):\n",
    "        response = requests.get(image_url)\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    \n",
    "    # Erkennen von Autos im Bild\n",
    "    output_path = os.path.join(results_dir, f'test_image_{i+1}_result.jpg')\n",
    "    boxes = detect_and_draw_cars(image_path, model, output_path)\n",
    "    \n",
    "    print(f\"Bild {i+1}: {len(boxes)} Autos erkannt\")\n",
    "    \n",
    "    # Anzeigen des Ergebnisses im Notebook\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(plt.imread(output_path))\n",
    "    plt.title(f\"Bild {i+1}: {len(boxes)} Autos erkannt\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2b: Erkennung von Autos auf drei weiteren Bildern aus dem Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Aufgabe 2b: Erkennung von Autos auf drei weiteren Bildern aus dem Internet...\")\n",
    "\n",
    "# Suchen nach Bildern mit mehreren Autos\n",
    "additional_images = [\n",
    "    \"https://cdn.pixabay.com/photo/2017/11/23/04/13/traffic-jam-2972156_1280.jpg\",\n",
    "    \"https://cdn.pixabay.com/photo/2017/08/01/09/34/car-2563902_1280.jpg\",\n",
    "    \"https://cdn.pixabay.com/photo/2017/08/06/12/08/car-2592150_1280.jpg\"\n",
    "]\n",
    "\n",
    "for i, image_url in enumerate(additional_images):\n",
    "    # Speichern des Bildes\n",
    "    image_path = os.path.join(images_dir, f'additional_image_{i+1}.jpg')\n",
    "    \n",
    "    # Herunterladen des Bildes, wenn es noch nicht existiert\n",
    "    if not os.path.exists(image_path):\n",
    "        response = requests.get(image_url)\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    \n",
    "    # Erkennen von Autos im Bild\n",
    "    output_path = os.path.join(results_dir, f'additional_image_{i+1}_result.jpg')\n",
    "    boxes = detect_and_draw_cars(image_path, model, output_path)\n",
    "    \n",
    "    print(f\"Zusätzliches Bild {i+1}: {len(boxes)} Autos erkannt\")\n",
    "    \n",
    "    # Anzeigen des Ergebnisses im Notebook\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(plt.imread(output_path))\n",
    "    plt.title(f\"Zusätzliches Bild {i+1}: {len(boxes)} Autos erkannt\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "In diesem Notebook haben wir:\n",
    "1. Ein trainiertes CNN-Modell zur Autoerkennung geladen\n",
    "2. Einen Sliding-Window-Algorithmus implementiert, um Autos in Bildern zu lokalisieren\n",
    "3. Multi-Scale-Erkennung verwendet, um Autos unterschiedlicher Größen zu erkennen\n",
    "4. Non-Maximum Suppression angewendet, um überlappende Bounding Boxes zu entfernen\n",
    "5. Die Erkennung auf verschiedenen Testbildern angewendet und die Ergebnisse visualisiert\n",
    "\n",
    "Der implementierte Ansatz ermöglicht die Erkennung von Autos in Bildern unterschiedlicher Größen und Perspektiven. Die Verwendung von Multi-Scale-Erkennung und Non-Maximum Suppression verbessert die Robustheit und Genauigkeit der Erkennung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Automerkennung auf Bildern abgeschlossen. Die Ergebnisse wurden im Verzeichnis 'results' gespeichert.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
